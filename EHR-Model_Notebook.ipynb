{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10451988,"sourceType":"datasetVersion","datasetId":6469943}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## EHR SUMMERIZER NOTEBOOK","metadata":{}},{"cell_type":"markdown","source":"#### OBJECTIVE :\n\n#### 1.) Summarize electronic health records (EHR) for doctors.\n#### 2.) Extract entities like symptoms, diagnoses, and medications.\n#### 3.) Analyze patient sentiment for patient notes or interactions.\n#### 4.) Provide a scalable pipeline for these tasks.","metadata":{}},{"cell_type":"markdown","source":"# Resources and Referances \n\n**[Visit Health Chain Platform for Model Integrations and Pipeline Setup](https://dotimplement.github.io/HealthChain/reference/pipeline/integrations/integrations/)**\n\n**[Visit Hugging Face For Pretrained Models and Pipeline](https://huggingface.co/medicalai/ClinicalBERT?library=transformers)**\n\n**[Visit Kaggle For Datasets](https://www.kaggle.com/code/gpreda/electronic-health-records-ehrs-data-exploration/input)**","metadata":{}},{"cell_type":"code","source":"!pip install nlp\n!pip install SpacyNLP\n!pip install pipeline\n!pip install healthchain\n!pip install spacy\n!python -m spacy download en_core_web_sm  # or another desired model\n!pip install transformers\n!pip install langchain\n!pip install langchain_community\n!pip install --upgrade langchain\n!pip install langchain-core \n!pip install transformers \n!pip install spacy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# First Approach Using HealthChainüßë‚Äç‚öïÔ∏èüßë‚Äç‚öïÔ∏è‚ù§Ô∏è‚Äçü©π‚ù§Ô∏è‚Äçü©π","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from langchain_core.output_parsers import StrOutputParser\n\n# # Replace JSONOutputParser with StrOutputParser\n# output_parser = StrOutputParser()\n# parsed_output = output_parser.parse(\"This is a sample output.\")\n# print(parsed_output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import json\n\n# class CustomJSONOutputParser:\n#     def parse(self, text):\n#         try:\n#             return json.loads(text)\n#         except json.JSONDecodeError as e:\n#             raise ValueError(f\"Invalid JSON format: {e}\")\n\n# # Example Usage\n# output_parser = CustomJSONOutputParser()\n# parsed_output = output_parser.parse('{\"key\": \"value\"}')\n# print(parsed_output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from healthchain.io.containers import Document\n# from healthchain.pipeline.base import Pipeline\n# from healthchain.pipeline.components.integrations import (\n#     SpacyNLP,\n#     HFTransformer,\n#     LangChainLLM,\n# )\n\n# from langchain_core.prompts import PromptTemplate\n# # from langchain_core.output_parsers import JSONOutputParser\n# # from langchain.llms import HuggingFaceLLM\n# import nlp\n# from langchain_core.output_parsers import StrOutputParser\n# import langchain\n# print(langchain.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Set up our components\n# spacy_component = SpacyNLP.from_model_id(\"en_core_web_sm\")\n# huggingface_component = HFTransformer.from_model_id(\n#     model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n#     task=\"sentiment-analysis\",\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Set up LangChain with a FakeListLLM\n# fake_llm = FakeListLLM(responses=[\"HealthChain: Powerful NLP pipeline builder.\"])\n# # Define the prompt template\n# prompt = PromptTemplate.from_template(\"Summarize the following text: {text}\")\n# # Create the LCEL chain\n# chain = prompt | fake_llm | StrOutputParser()\n# langchain_component = LangChainLLM(chain=chain, task=\"summarization\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Build our pipeline\n# pipeline = Pipeline()\n# pipeline.add_node(spacy_component)\n# pipeline.add_node(huggingface_component)\n# pipeline.add_node(langchain_component)\n# pipeline.build()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Process a document\n# doc = Document(\"HealthChain makes it easy to build powerful NLP pipelines!\")\n# processed_doc = pipeline(doc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Let's see what we got!\n# spacy_doc = processed_doc.nlp.get_spacy_doc()\n# sentiment = processed_doc.models.get_output(\"huggingface\", \"sentiment-analysis\")\n# summary = processed_doc.models.get_output(\"langchain\", \"summarization\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(f\"Tokens: {[token.text for token in spacy_doc]}\")\n# print(f\"Sentiment: {sentiment}\")\n# print(f\"Summary: {summary}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Seond Approach Building Custom Pipeline ","metadata":{}},{"cell_type":"code","source":"# Pipeline Workflow\n\n# Data Ingestion: Load EHRs in various formats (e.g., text, JSON, or HL7).\n\n# Preprocessing:\n\n# Tokenization and sentence segmentation.\n\n# Anonymization of sensitive data.\n\n# Prompt Engineering to guide the model.\n\n#  NLP Tasks:\n\n# Entity recognition for extracting symptoms, diagnoses, and medications.\n\n# Summarization of medical records.\n\n# Sentiment analysis of patient notes.\n\n# Scalability: Implement scalable components using cloud platforms or distributed systems.\n\n# User Interaction: Provide outputs in user-friendly formats via a web interface.\n\n# Report Generation: Generate concise summaries and visual dashboards.\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:20:00.662661Z","iopub.execute_input":"2025-01-15T12:20:00.663062Z","iopub.status.idle":"2025-01-15T12:20:00.667307Z","shell.execute_reply.started":"2025-01-15T12:20:00.663034Z","shell.execute_reply":"2025-01-15T12:20:00.666116Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Pipeline Components\n# Data Ingestion and Preprocessing\n\n# Input: Raw medical records in text or JSON format.\n# Output: Cleaned and tokenized text.\n# Named Entity Recognition (NER)\n\n# Extract medical entities such as symptoms, medications, and diagnoses.\n# Text Summarization\n\n# Summarize long medical records into concise and readable formats.\n# Sentiment Analysis\n\n# Analyze patient notes to determine sentiment.\n# Pipeline Orchestration\n\n# Combine all components into a unified pipeline.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# import re\n\n# def preprocess_text(text):\n#     \"\"\"\n#     Cleans and preprocesses raw medical text.\n#     \"\"\"\n#     # Remove sensitive information (e.g., names, IDs)\n#     text = re.sub(r\"Patient Name: \\w+\", \"Patient Name: [REDACTED]\", text)\n#     text = re.sub(r\"[^\\w\\s.,]\", \"\", text)  # Remove special characters\n#     text = text.strip()\n#     return text\n\n# # Example Input\n# raw_text = \"\"\"\n# Patient Name: John Doe\n# Symptoms: Fever, headache, fatigue.\n# Diagnosis: Viral infection.\n# Prescribed Medications: Paracetamol, Ibuprofen.\n# \"\"\"\n\n# cleaned_text = preprocess_text(raw_text)\n# print(cleaned_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # If spacy dosent install use it from the AWS Cloud services for Version Downloading \n# !pip install scispacy\n# !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_lg-0.4.0.tar.gz\n\n# import spacy\n\n# # Load SciSpacy model\n# nlp = spacy.load(\"en_core_sci_sm\")\n# spacy_component = SpacyNLP.from_model_id(\"en_core_web_sm\")\n# def extract_entities(text):\n#     \"\"\"\n#     Extracts medical entities such as symptoms, medications, and diagnoses.\n#     \"\"\"\n#     doc = nlp(text)\n#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n#     return entities\n\n# # Example Usage\n# entities = extract_entities(cleaned_text)\n# print(\"Extracted Entities:\", entities)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install nlp\n!pip install SpacyNLP\n!pip install pipeline\n!pip install healthchain\n!pip install spacy\n!python -m spacy download en_core_web_sm  # or another desired model\n!pip install transformers\n!pip install langchain\n!pip install langchain_community\n!pip install --upgrade langchain\n!pip install langchain-core \n!pip install transformers \n!pip install spacy\n!pip install fitz\n!pip install frontend \n!pip install PyMuPDF","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install transformers spacy\nimport re\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom transformers import pipeline\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import pipeline as hf_pipeline  # Rename to avoid conflict\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\nimport torch\nfrom transformers import LongformerTokenizer, LongformerForSequenceClassification\nimport numpy as np\nimport pandas as pd\nimport re\nimport json\n# import fitz  # PyMuPDF (for extracting text from PDF)\nimport os\n# from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelForSeq2SeqLM\n# # from typing import Union\nimport fitz\nimport os\nimport fitz\nimport json\nimport logging\nimport os\nimport logging\nimport json\nimport fitz  # PyMuPDF\nfrom pdf2image import convert_from_path\nimport pytesseract\nfrom PIL import Image\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport re\nimport logging\nlogging.basicConfig(level=logging.INFO)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load ALL necessary Models\n# Load Sentiment Analysis Pipeline\nsentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n\n# Load BioBERT Model\n\nner_model = AutoModelForTokenClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\nner_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n\n# Create an NER Pipeline\n# ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer)\nner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, grouped_entities=True)\n\n\n# Load T5 Model for Summarization\nsummarization_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")  # Use 't5-large' for better performance\nsummarization_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n\n\n# Load models for Context-Aware Sentiment Analysis\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\nsentiment_model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n\n# Load Longformer model for handling long text\nlongformer_tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\nlongformer_model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\")\n\n# # Pipeline for Sentence Level Sentiment Analysis (DistilBERT)\n# sentiment_pipeline = pipeline(\"sentiment-analysis\", model=sentiment_model, tokenizer=tokenizer)\n\n# Initialize the GPT-2 model and tokenizer from Hugging Face\nmodel_name = \"gpt2\"  # You can also use \"gpt2-medium\", \"gpt2-large\", or \"gpt2-xl\" for larger models\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline, TFAutoModelForTokenClassification, TFAutoModelForSeq2SeqLM, AutoTokenizer\nimport os\nfrom transformers import TFAutoModelForSequenceClassification\nfrom transformers import TFAutoModelForCausalLM\n\n\n# Directory to save models\nsave_directory = \"./saved_models\"\nos.makedirs(save_directory, exist_ok=True)\n\n# Sentiment Pipeline (DistilBERT-based)\nsentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\nsentiment_pipeline.model.save_pretrained(os.path.join(save_directory, \"sentiment_model\"))\nsentiment_pipeline.tokenizer.save_pretrained(os.path.join(save_directory, \"sentiment_model\"))\n\n# BioBERT NER - Convert to TensorFlow model\nmodel_name = \"dmis-lab/biobert-base-cased-v1.1\"\nner_model = TFAutoModelForTokenClassification.from_pretrained(model_name, from_pt=True)  # Load from PyTorch weights\nner_tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Save BioBERT as TensorFlow model in SavedModel format (default format)\nner_model.save_pretrained(os.path.join(save_directory, \"biobert_ner_model\"))\nner_model.save(os.path.join(save_directory, \"biobert_ner_model\"))  # SavedModel format (no .h5)\n\n# Save tokenizer\nner_tokenizer.save_pretrained(os.path.join(save_directory, \"biobert_ner_model\"))\n\n# T5 Summarization Model - Convert to TensorFlow model\nsummarization_model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\nsummarization_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n\n# Save T5 as TensorFlow model in SavedModel format\nsummarization_model.save_pretrained(os.path.join(save_directory, \"t5_summarization_model\"))\nsummarization_model.save(os.path.join(save_directory, \"t5_summarization_model\"))  # SavedModel format\nsummarization_tokenizer.save_pretrained(os.path.join(save_directory, \"t5_summarization_model\"))\n\n# Longformer - Convert to TensorFlow model\nlongformer_model = TFAutoModelForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\")\nlongformer_tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n\n# Save Longformer as TensorFlow model in SavedModel format\nlongformer_model.save_pretrained(os.path.join(save_directory, \"longformer_model\"))\nlongformer_model.save(os.path.join(save_directory, \"longformer_model\"))  # SavedModel format\nlongformer_tokenizer.save_pretrained(os.path.join(save_directory, \"longformer_model\"))\n\n# GPT-2 - Convert to TensorFlow model\ngpt2_model = TFAutoModelForCausalLM.from_pretrained(\"gpt2\")\ngpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n\n# Save GPT-2 as TensorFlow model in SavedModel format\ngpt2_model.save_pretrained(os.path.join(save_directory, \"gpt2_model\"))\ngpt2_model.save(os.path.join(save_directory, \"gpt2_model\"))  # SavedModel format\ngpt2_tokenizer.save_pretrained(os.path.join(save_directory, \"gpt2_model\"))\n\nprint(f\"Models saved in TensorFlow SavedModel format at {save_directory}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Github routh Kaggle implmeenetation ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:14:27.047202Z","iopub.execute_input":"2025-01-15T12:14:27.047412Z","iopub.status.idle":"2025-01-15T12:14:27.052068Z","shell.execute_reply.started":"2025-01-15T12:14:27.047390Z","shell.execute_reply":"2025-01-15T12:14:27.051173Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# !git clone https://github.com/Blacksujit/Deep-Learning-Specialization-Repo.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %cd ..","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !cp -r /kaggle/working/Deep-Learning-Specialization-Repo /kaggle/working/Deep-Learning-Specialization-Repo/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T20:36:01.125337Z","iopub.execute_input":"2025-01-13T20:36:01.125834Z","iopub.status.idle":"2025-01-13T20:36:01.131139Z","shell.execute_reply.started":"2025-01-13T20:36:01.125799Z","shell.execute_reply":"2025-01-13T20:36:01.129741Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"# %cd Deep-Learning-Specialization-Repo","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !git add .\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Github rough implementation completed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:14:30.957285Z","iopub.execute_input":"2025-01-15T12:14:30.957588Z","iopub.status.idle":"2025-01-15T12:14:30.961650Z","shell.execute_reply.started":"2025-01-15T12:14:30.957564Z","shell.execute_reply":"2025-01-15T12:14:30.960478Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Move the model to the GPU if available (optional but recommended for large models)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_FILE_SIZE = 10 * 1024 * 1024  # 10 MB","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate_file_size(file_path: str) -> None:\n    file_size = os.path.getsize(file_path)\n    if file_size > MAX_FILE_SIZE:\n        raise ValueError(f\"File is too large ({file_size} bytes). Maximum allowed size is {MAX_FILE_SIZE} bytes.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_text_from_file(file_path: str) -> str:\n    \"\"\"\n    Extracts text from a file based on its type (txt, pdf, json).\n    \"\"\"\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"The file does not exist: {file_path}\")\n    \n    # Validate file size\n    validate_file_size(file_path)\n\n    file_extension = os.path.splitext(file_path)[1].lower()\n    logging.info(f\"Extracting text from {file_path} with extension {file_extension}\")\n\n    if file_extension == '.txt':\n        return extract_text_from_txt(file_path)\n    \n    elif file_extension == '.pdf':\n        return extract_text_from_pdf(file_path)\n    \n    elif file_extension == '.json':\n        return extract_text_from_json(file_path)\n    \n    else:\n        raise ValueError(f\"Unsupported file format: {file_extension}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_text_from_txt(file_path: str) -> str:\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            text = f.read()\n        return text\n    except Exception as e:\n        raise RuntimeError(f\"Error reading text file: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_file: str) -> str:\n    \"\"\"\n    Extracts text from a PDF file using PyMuPDF (fitz).\n    \"\"\"\n    try:\n        doc = fitz.open(pdf_file)\n        text = \"\"\n        for page in doc:\n            text += page.get_text(\"text\")\n        if not text.strip():  # If no text found, use OCR\n            images = convert_from_path(pdf_file)\n            text = ' '.join([pytesseract.image_to_string(img) for img in images])\n            logging.warning(f\"Using OCR for PDF: {pdf_file}\")\n        return text\n    except Exception as e:\n        raise RuntimeError(f\"Error reading PDF file: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_text_from_json(json_file: str) -> str:\n    \"\"\"\n    Extracts text content from a JSON file.\n    \"\"\"\n    try:\n        with open(json_file, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        return data.get(\"text\", \"\")\n    except json.JSONDecodeError as e:\n        raise RuntimeError(f\"Error parsing JSON file: {e}\")\n    except Exception as e:\n        raise RuntimeError(f\"Error reading JSON file: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_text(text: str, to_lowercase: bool = True) -> str:\n    \"\"\"\n    Cleans and preprocesses raw medical text.\n    Enhancements:\n    - Anonymizes sensitive data (names, dates, IDs, phone numbers, emails).\n    - Handles medical-specific data: ICD codes, test results, vitals, etc.\n    - Removes unwanted special characters.\n    - Normalizes whitespace.\n    - Converts to lowercase (optional).\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"Input text must be a string.\")\n    \n    logging.info(\"Starting text preprocessing...\")\n\n    # Anonymize patient names\n    text = re.sub(r\"(Patient(?: Name)?:)\\s+[A-Za-z ]+\", r\"\\1 [REDACTED]\", text)\n    logging.info(\"Patient names anonymized.\")\n\n    # Anonymize dates\n    text = re.sub(r\"\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b\", \"[DATE REDACTED]\", text)\n    text = re.sub(r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{1,2}, \\d{4}\\b\", \"[DATE REDACTED]\", text, flags=re.IGNORECASE)\n    text = re.sub(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\", \"[DATE REDACTED]\", text)\n    logging.info(\"Dates anonymized.\")\n\n    # Anonymize IDs (e.g., Medical Record ID)\n    text = re.sub(r\"(Medical Record ID|Patient ID|Case ID): \\d+\", r\"\\1: [REDACTED]\", text)\n    logging.info(\"IDs anonymized.\")\n\n    # Anonymize phone numbers\n    text = re.sub(r\"\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\", \"[PHONE REDACTED]\", text)\n    logging.info(\"Phone numbers anonymized.\")\n\n    # Anonymize email addresses\n    text = re.sub(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\", \"[EMAIL REDACTED]\", text)\n    logging.info(\"Emails anonymized.\")\n\n    # Anonymize ICD/Diagnosis Codes (e.g., \"ICD-10: E11.9\")\n    text = re.sub(r\"(ICD(?:-10|-9)?:?\\s?)[A-Za-z0-9.]+\", r\"\\1[REDACTED]\", text)\n    logging.info(\"ICD codes anonymized.\")\n\n    # Anonymize prescription drug names (e.g., \"Medication: Paracetamol\")\n    text = re.sub(r\"(Medication|Drug|Prescription):\\s+[A-Za-z0-9., ]+\", r\"\\1: [REDACTED]\", text)\n    logging.info(\"Drug and prescription names anonymized.\")\n\n    # Anonymize health metrics (e.g., \"BP: 120/80\", \"BMI: 24.5\")\n    text = re.sub(r\"(BP|Blood Pressure|BMI|Heart Rate|Respiratory Rate):\\s?\\d{1,3}(/\\d{1,3})?\", r\"\\1: [REDACTED]\", text)\n    logging.info(\"Health metrics anonymized.\")\n\n    # Anonymize lab/test results (e.g., \"HbA1c: 7.5%\")\n    text = re.sub(r\"(HbA1c|Glucose|Cholesterol|Triglycerides):?\\s?\\d{1,3}(\\.\\d+)?%?\", r\"\\1: [REDACTED]\", text)\n    logging.info(\"Lab and test results anonymized.\")\n\n    # Anonymize insurance/billing information (e.g., \"Policy No: 123456789\")\n    text = re.sub(r\"(Insurance Policy|Policy No|Billing ID):\\s?\\d+\", r\"\\1: [REDACTED]\", text)\n    logging.info(\"Insurance and billing information anonymized.\")\n\n    # Anonymize room/hospital identifiers (e.g., \"Room No: 12A\")\n    text = re.sub(r\"(Room No|Hospital ID):\\s?[A-Za-z0-9]+\", r\"\\1: [REDACTED]\", text)\n    logging.info(\"Room and hospital identifiers anonymized.\")\n\n    # Remove unwanted special characters\n    text = re.sub(r\"[^\\w\\s.,%-]\", \"\", text)\n    logging.info(\"Special characters removed.\")\n\n\n    # Anonymize General Medical Terms\n    text = re.sub(r\"\\b(patient|hospital|doctor|nurse|specialist|clinic|facility|caregiver|medical history|referral)\\b\", \"[REDACTED]\", text)\n\n    # Anonymize Medical Conditions / Diagnoses\n    text = re.sub(r\"\\b(cancer|hypertension|diabetes|heart disease|stroke|asthma|COPD|pneumonia|migraine|epilepsy)\\b\", \"[DIAGNOSIS REDACTED]\", text)\n\n    # Anonymize Medical Procedures & Surgeries\n    text = re.sub(r\"\\b(surgery|operation|biopsy|chemo|radiation therapy|endoscopy|CT scan|MRI|X-ray)\\b\", \"[PROCEDURE REDACTED]\", text)\n\n    # Anonymize Medications / Drugs\n    text = re.sub(r\"\\b(paracetamol|ibuprofen|aspirin|insulin|metformin|amoxicillin|prednisone|lipitor|antibiotic|painkillers)\\b\", \"[MEDICATION REDACTED]\", text)\n\n    # Anonymize Health Metrics & Vitals\n    text = re.sub(r\"\\b(blood pressure|BP|heart rate|BMI|pulse rate|respiratory rate|oxygen saturation|glucose level|cholesterol level|HbA1c)\\b\", \"[HEALTH METRIC REDACTED]\", text)\n\n    # Anonymize Test Results\n    text = re.sub(r\"\\b(CBC|ECG|X-ray result|CT scan result|MRI result|blood test|urine test|pregnancy test)\\b\", \"[TEST RESULT REDACTED]\", text)\n\n    # Anonymize Personal Information\n    text = re.sub(r\"\\b(patient name|address|phone number|email|social security number|insurance ID)\\b\", \"[REDACTED]\", text)\n\n    # Anonymize Procedural Terms\n    text = re.sub(r\"\\b(emergency|urgent care|hospitalization|outpatient|inpatient)\\b\", \"[PROCEDURE REDACTED]\", text)\n\n    # Normalize whitespace\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n\n    # Convert to lowercase if enabled\n    if to_lowercase:\n        text = text.lower()\n    \n    logging.info(\"Text preprocessing complete.\")\n    return text\n\n# # Example Input\n# raw_text = \"\"\"\n# Patient Name: Black Shadow\n# Medical Record ID: 12345\n# Phone: (123) 456-7890\n# Email: black.shadow@example.com\n# Diagnosis: The patient is diagnosed with cancer on 01/01/2023.\n\n# \"\"\"\n# cleaned_text = preprocess_text(raw_text)\n# print(cleaned_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# New Prompt Engineering Step \n\ndef apply_prompt_engineering(cleaned_text: str) -> dict:\n    \"\"\"\n    Applies prompt engineering to guide the language model in generating outputs based on the cleaned medical text.\n    Uses a pretrained GPT-2 model to generate results.\n    \"\"\"\n\n    logging.info(\"Applying prompt engineering to the cleaned text...\")\n\n    prompts = [\n    \"Summarize the medical document in a few sentences.\",\n    \"Extract key medical conditions, diseases, or diagnoses mentioned in the document.\",\n    \"Identify and list any medical procedures or surgeries discussed in the document.\",\n    \"Highlight any prescribed medications or treatments mentioned in the document.\",\n    \"Extract patient demographic information, if available.\",\n    \"Summarize lab and test results mentioned in the document.\",\n    \"Extract vital signs and health metrics (e.g., BP, Heart Rate, BMI) from the document.\",\n    \"Identify any insurance or billing information in the document.\",\n    \"Categorize and list the medications and treatments prescribed in the document.\",\n    \"Extract family medical history, if provided.\",\n    \"Identify allergies or sensitivities mentioned in the document.\",\n    \"Identify and list any immunizations or vaccines discussed in the document.\",\n    \"Extract emergency contact information if provided in the document.\",\n    \"Summarize the patient‚Äôs medical history.\",\n    \"Identify and list any smoking or alcohol consumption habits mentioned in the document.\",\n    \"Extract any surgical history, including dates and types of procedures.\",\n    \"Identify and list the patient's chronic conditions.\",\n    \"List any referrals to specialists or healthcare providers mentioned in the document.\",\n    \"Summarize any physical therapy or rehabilitation information provided.\",\n    \"Identify any genetic information, such as inherited conditions, if mentioned.\",\n    \"Extract patient‚Äôs height, weight, and body mass index (BMI), if available.\",\n    \"Identify any recent hospitalizations or inpatient admissions.\",\n    \"Summarize any mental health concerns or diagnoses in the document.\",\n    \"Extract information about the patient‚Äôs social history, including occupation and lifestyle factors.\",\n    \"Identify any laboratory test names (e.g., blood tests, cultures) mentioned in the document.\",\n    \"Extract the results of any diagnostic imaging (e.g., X-rays, MRIs, CT scans).\",\n    \"List any medical devices mentioned in the document (e.g., pacemakers, prosthetics).\",\n    \"Identify any fertility or reproductive health information mentioned.\",\n    \"Summarize any substance abuse history, including alcohol, drugs, or tobacco use.\",\n    \"Identify any hereditary diseases or genetic markers mentioned.\",\n    \"Summarize the patient's risk factors for chronic conditions (e.g., obesity, hypertension).\",\n    \"Identify the patient's current and past medications, including dosages.\",\n    \"List any over-the-counter medications or supplements mentioned.\",\n    \"Identify any changes in the patient's medications or dosage history.\",\n    \"Summarize any dietary restrictions or nutrition-related information provided.\",\n    \"Identify any issues related to the patient‚Äôs sleep patterns or disorders.\",\n    \"Summarize any vision or hearing impairments mentioned in the document.\",\n    \"Extract any dental health information, including treatments or issues.\",\n    \"Summarize the patient's blood pressure readings and any relevant trends.\",\n    \"Identify and list any test results related to the liver, kidney, or heart functions.\",\n    \"Extract information on blood glucose levels, including diabetes-related data.\",\n    \"Summarize the patient‚Äôs neurological health, including any diagnoses or conditions.\",\n    \"Identify any respiratory issues or diagnoses (e.g., asthma, COPD).\",\n    \"Extract any information related to the patient‚Äôs cardiovascular health (e.g., heart disease).\",\n    \"Summarize any information on the patient‚Äôs gastrointestinal health (e.g., IBS, ulcers).\",\n    \"List any skin conditions or dermatological treatments mentioned.\",\n    \"Identify any chronic pain conditions and their management.\",\n    \"Summarize the patient's immunological health (e.g., autoimmune diseases, allergies).\",\n    \"List any psychological or psychiatric evaluations or treatments discussed.\",\n    \"Extract information on any cancer diagnoses, treatments, or outcomes.\",\n    \"Identify and summarize any infectious diseases or conditions diagnosed.\",\n    \"Extract any family planning or contraception-related information.\",\n    \"Identify any alternative or complementary treatments mentioned.\",\n    \"List any follow-up visits or procedures recommended for the patient.\",\n    \"Summarize the treatment plan provided in the document, including medications and interventions.\",\n    \"Extract any notes regarding the patient‚Äôs recovery or rehabilitation process.\",\n    \"Identify any concerns or red flags noted by the healthcare provider.\",\n    \"List the patient's immunization history, including vaccine types and dates.\",\n    \"Extract any cardiovascular risk assessments or screenings performed.\",\n    \"Summarize any smoking cessation or alcohol reduction programs mentioned.\",\n    \"Identify any genetic testing or counseling discussed.\",\n    \"List any healthcare screenings, such as mammograms or colonoscopies, discussed in the document.\",\n    \"Summarize any pain management strategies mentioned, including medications and non-pharmacological treatments.\",\n    \"Identify any treatments for mental health or behavioral conditions (e.g., anxiety, depression).\",\n    \"Summarize any reproductive health concerns, including fertility treatments or gynecological conditions.\",\n    \"Extract any end-of-life care or palliative care discussions in the document.\",\n    \"Summarize the patient's rehabilitation or physical therapy plan.\",\n    \"Identify any therapies or treatments for musculoskeletal conditions (e.g., arthritis, osteoporosis).\",\n    \"Summarize any skin care treatments or dermatology-related information.\",\n    \"Identify any diagnostic or therapeutic interventions for mental health issues.\",\n    \"Extract information regarding the patient's compliance with the treatment plan.\",\n    \"Summarize any surgical complications or adverse reactions described.\",\n    \"Identify any references to clinical trials or experimental treatments the patient is participating in.\",\n    \"Extract information on any medications or treatments being discontinued or adjusted.\",\n    \"Summarize any preventive health measures, such as screenings, vaccinations, or wellness checks.\",\n    \"List any lifestyle modifications suggested by the healthcare provider (e.g., exercise, diet).\",\n    \"Summarize any genetic counseling or testing related to specific conditions.\",\n    \"Extract information on the patient's response to treatment or therapies.\",\n    \"Identify any concerns or recommendations regarding the patient‚Äôs mental health status.\",\n    \"Summarize any concerns related to maternal or fetal health in pregnancy-related documents.\",\n    \"Identify any diagnostic methods or tests used to evaluate the patient‚Äôs condition (e.g., bloodwork, imaging).\",\n    \"Extract any detailed notes on the patient's work or occupational health status.\",\n    \"Summarize the patient‚Äôs compliance with prescribed medical treatments or procedures.\",\n    \"Identify any concerns related to the patient's post-operative or post-procedural care.\",\n    \"Summarize the patient‚Äôs functional status and ability to perform daily activities.\",\n    \"List any lifestyle or behavioral factors that might be contributing to the patient‚Äôs condition.\",\n    \"Identify any specific dietary recommendations or restrictions discussed in the document.\",\n    \"Summarize any alternative medicine or holistic treatments mentioned in the document.\",\n    \"Extract any references to peer-reviewed studies or clinical guidelines used in the treatment decisions.\",\n    \"Identify any legal, ethical, or consent-related issues discussed in the document.\"\n\n    ]\n    \n    # Initialize the dictionary to store results\n    results = {}\n\n    # For each prompt, we use the model to generate a response\n    for prompt in prompts:\n        try:\n            # Prepend the cleaned text to the prompt\n            full_input = f\"{prompt}\\n\\nText: {cleaned_text}\"\n\n            # Tokenize the input and prepare it for the model\n            inputs = tokenizer(full_input, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n            \n            # Generate the output\n            outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1, no_repeat_ngram_size=2, top_p=0.95, temperature=0.7)\n\n            # Decode the output text\n            result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n\n            # Store the result in the dictionary\n            results[prompt] = result\n            logging.info(f\"Prompt '{prompt}' processed successfully.\")\n        \n        except Exception as e:\n            logging.error(f\"Error while processing prompt '{prompt}': {str(e)}\")\n            results[prompt] = f\"Error: {str(e)}\"\n\n    logging.info(\"Prompt engineering applied successfully.\")\n    return results\n\n\n# # Example Usage\n# raw_text = \"\"\"\n# Patient Name: Black Shadow\n# Medical Record ID: 12345\n# Phone: (123) 456-7890\n# Email: black.shadow@example.com\n# Diagnosis: The patient is diagnosed with cancer on 01/01/2023.\n# Medication: Paracetamol, 500mg\n# Test Result: HbA1c: 7.5%\n# BP: 120/80\n# \"\"\"\n# # Step 1: Preprocess the text\n# cleaned_text = preprocess_text(raw_text)\n\n# # Step 2: Apply prompt engineering to guide model output\n# prompt_results = apply_prompt_engineering(cleaned_text)\n\n# # Output the results\n# for prompt, result in prompt_results.items():\n#     print(f\"{prompt}:\\n{result}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_entities(text):\n    \"\"\"\n    Extracts entities using keyword-based matching for symptoms, diagnoses, and medications.\n    \n    Args:\n        text (str): Input medical text for entity extraction.\n\n    Returns:\n        dict: Extracted entities grouped by type (e.g., symptoms, diagnoses, medications).\n    \"\"\"\n\n    # # If the input is structured and contains entities already\n    # if isinstance(results, dict) and 'entities' in results:\n    #     return results['entities']\n\n    # else:\n    #     text = apply_prompt_engineering(resulta)\n\n\n    # Full keyword lists for symptoms, diagnoses, and medications (from your provided lists)\n    # # If the input is raw text, perform the entity extraction\n    # if isinstance(results, str):\n    #     text = results\n        \n    symptom_keywords = set([\n        \"pain\", \"fever\", \"cough\", \"headache\", \"fatigue\", \"nausea\", \"dizziness\", \"sore\", \"chills\", \n        \"swelling\", \"tired\", \"vomiting\", \"diarrhea\", \"constipation\", \"drowsiness\", \"sweating\", \"appetite loss\", \n        \"confusion\", \"weakness\", \"bleeding\", \"shortness of breath\", \"chest pain\", \"back pain\", \"abdominal pain\", \n        \"muscle aches\", \"joint pain\", \"coughing up blood\", \"sore throat\", \"stomach cramps\", \"dysphagia\", \"anorexia\", \n        \"urinary retention\", \"joint stiffness\", \"itching\", \"rash\", \"dysuria\", \"hematuria\", \"palpitations\", \n        \"dizziness\", \"tremors\", \"memory loss\", \"insomnia\", \"night sweats\", \"cold hands\", \"fatigue\", \"burning sensation\", \n        \"bloating\", \"difficulty breathing\", \"weight loss\", \"weight gain\", \"numbness\", \"tingling\", \"lightheadedness\", \n        \"fainting\", \"ear pain\", \"tinnitus\", \"confusion\", \"uncontrolled shaking\", \"mood swings\", \"irregular heartbeat\", \n        \"chronic fatigue\", \"muscle weakness\", \"skin rash\", \"joint swelling\", \"shortness of breath\", \"palpitations\", \n        \"urinary incontinence\", \"frequent urination\", \"difficulty swallowing\", \"blurry vision\", \"yellowing skin\", \n        \"chronic cough\", \"leg swelling\", \"facial swelling\", \"neck stiffness\", \"stomach bloating\", \"difficulty sleeping\", \n        \"cold sweats\", \"feeling faint\", \"dehydration\", \"slow heartbeat\", \"congestion\", \"runny nose\", \"sinus headache\", \n        \"frequent headaches\", \"gastrointestinal discomfort\", \"liver pain\", \"hemoptysis\", \"chronic pain\", \"frequent thirst\"\n    ])\n    \n    diagnosis_keywords = set([\n        \"cancer\", \"diabetes\", \"heart disease\", \"stroke\", \"asthma\", \"pneumonia\", \"arthritis\", \"hypertension\", \n        \"COPD\", \"depression\", \"anxiety\", \"influenza\", \"tuberculosis\", \"chronic obstructive pulmonary disease\", \"HIV\", \n        \"hypertensive heart disease\", \"gastritis\", \"stroke\", \"schizophrenia\", \"epilepsy\", \"osteoporosis\", \n        \"chronic kidney disease\", \"chronic pain\", \"fibromyalgia\", \"sleep apnea\", \"obesity\", \"bipolar disorder\", \n        \"Parkinson's disease\", \"dementia\", \"multiple sclerosis\", \"sickle cell anemia\", \"irritable bowel syndrome\", \n        \"hepatitis\", \"cirrhosis\", \"hypothyroidism\", \"hyperthyroidism\", \"urinary tract infection\", \"nephropathy\", \n        \"stroke\", \"Alzheimer's disease\", \"autoimmune disorder\", \"autoimmune disease\", \"HIV/AIDS\", \"cardiomyopathy\", \n        \"peripheral neuropathy\", \"gout\", \"lupus\", \"celiac disease\", \"pancreatitis\", \"colitis\", \"cancer\", \"renal failure\", \n        \"bipolar disorder\", \"schizophrenia\", \"Crohn's disease\", \"tuberculosis\", \"pneumonia\", \"mental illness\", \n        \"emphysema\", \"anemia\", \"Cushing's syndrome\", \"Addison's disease\", \"sickle cell disease\", \"sepsis\", \"septicemia\", \n        \"heart attack\", \"arrhythmia\", \"heart failure\", \"chronic fatigue syndrome\", \"malaria\", \"chickenpox\", \n        \"tuberculosis\", \"meningitis\", \"gonorrhea\", \"syphilis\", \"hepatitis C\", \"HIV infection\", \"gonorrhea\", \n        \"urinary tract infection\", \"psoriasis\", \"chronic bronchitis\", \"eczema\", \"dermatitis\", \"hypertension\", \"stroke\", \n        \"myocardial infarction\", \"cirrhosis\", \"brain tumor\", \"epileptic seizures\", \"lymphoma\", \"melanoma\", \"bacterial infection\"\n    ])\n    \n    medication_keywords = set([\n        \"ibuprofen\", \"aspirin\", \"paracetamol\", \"amoxicillin\", \"metformin\", \"insulin\", \"acetaminophen\", \"naproxen\", \n        \"hydrocodone\", \"morphine\", \"antibiotics\", \"prednisone\", \"loratadine\", \"dextromethorphan\", \"fentanyl\", \n        \"sertraline\", \"fluoxetine\", \"alprazolam\", \"omeprazole\", \"lisinopril\", \"hydrochlorothiazide\", \"gabapentin\", \n        \"diclofenac\", \"cetirizine\", \"diphenhydramine\", \"clindamycin\", \"azithromycin\", \"levothyroxine\", \"amlodipine\", \n        \"warfarin\", \"hydroxychloroquine\", \"clopidogrel\", \"hydrocodone\", \"acetaminophen\", \"phenytoin\", \"topiramate\", \n        \"amlodipine\", \"losartan\", \"prednisolone\", \"carbamazepine\", \"valacyclovir\", \"antihistamine\", \"citalopram\", \n        \"zoloft\", \"paroxetine\", \"fluticasone\", \"albuterol\", \"salbutamol\", \"alendronate\", \"ranitidine\", \"esomeprazole\", \n        \"metoprolol\", \"lorazepam\", \"levothyroxine\", \"meloxicam\", \"simvastatin\", \"atorvastatin\", \"metformin\", \n        \"nifedipine\", \"lisinopril\", \"bupropion\", \"esomeprazole\", \"tramadol\", \"gabapentin\", \"cyclobenzaprine\", \n        \"clonazepam\", \"flunisolide\", \"captopril\", \"dexamethasone\", \"tamsulosin\", \"fluconazole\", \"amoxicillin\", \n        \"lorazepam\", \"digoxin\", \"hydrocodone\", \"doxycycline\", \"ketoconazole\", \"azithromycin\", \"miconazole\", \n        \"propranolol\", \"nystatin\", \"phenobarbital\", \"fluconazole\", \"dapoxetine\", \"nitroglycerin\", \"pantoprazole\", \n        \"cimetidine\", \"levofloxacin\", \"ivermectin\", \"sildenafil\", \"carvedilol\", \"calcium carbonate\", \"hydrochlorothiazide\", \n        \"spironolactone\", \"metoclopramide\", \"albuterol\", \"zolpidem\", \"tizanidine\", \"trazodone\", \"famotidine\", \n        \"prednisolone\", \"methylprednisolone\", \"hydrocortisone\", \"clomipramine\", \"dantrolene\", \"lamotrigine\", \n        \"valsartan\", \"topiramate\", \"methadone\", \"hydroxychloroquine\"\n    ])\n    \n    # Tokenize the input text by words (using regex for better tokenization)\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n\n    # Initialize categories\n    categorized_entities = {\"symptoms\": set(), \"diagnoses\": set(), \"medications\": set()}\n\n    # Classify words based on keyword matching\n    for word in words:\n        if word in symptom_keywords:\n            categorized_entities[\"symptoms\"].add(word)\n        elif word in diagnosis_keywords:\n            categorized_entities[\"diagnoses\"].add(word)\n        elif word in medication_keywords:\n            categorized_entities[\"medications\"].add(word)\n\n    # Convert sets back to lists for the output\n    for category in categorized_entities:\n        categorized_entities[category] = list(categorized_entities[category])\n\n    return categorized_entities\n\n# # Test with your raw input text\n# raw_text = \"\"\"\n#     The patient is diagnosed with severe chest pain, high fever, and shortness of breath due to pneumonia. \n#     Medications prescribed include ibuprofen for pain and amoxicillin for the infection.\n#     \"\"\"\n# results = extract_entities(raw_text)\n# print(results)\n# Example usage\n# raw_text = \"\"\"\n# The patient is diagnosed with hypertension and diabetes. The prescribed medication is metformin, 500mg, and paracetamol for pain.\n# Symptoms include fatigue, dizziness, and shortness of breath.\n# \"\"\"\n\n# # Step 1: Apply prompt engineering or preprocess the text\n# cleaned_text = preprocess_text(raw_text)  # Assuming a preprocessing function is used\n\n# # Step 2: Extract entities based on symptoms, diagnoses, and medications\n# entities = extract_entities(cleaned_text)\n\n# # Output the extracted entities\n# print(entities)\n\n# # Example results dictionary (entities already identified)\n# results = {\n#     \"entities\": {\n#         \"symptoms\": [\"fatigue\", \"dizziness\", \"shortness of breath\"],\n#         \"diagnoses\": [\"hypertension\", \"diabetes\"],\n#         \"medications\": [\"metformin\", \"paracetamol\"]\n#     }\n# }\n\n# # Directly return entities from the results dictionary\n# extracted_entities = extract_entities(results)\n\n# # Output the extracted entities\n# print(\"Extracted Symptoms:\", extracted_entities['symptoms'])\n# print(\"Extracted Diagnoses:\", extracted_entities['diagnoses'])\n# print(\"Extracted Medications:\", extracted_entities['medications'])\n# print(extracted_entities)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# # Load pre-trained model and tokenizer for T5 summarization\n# summarization_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n# summarization_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n\ndef summarize_text(text, max_input_length=1024, max_summary_length=150, temperature=1.0, top_k=50, top_p=0.95, beam_width=8, no_repeat_ngram_size=2):\n    \"\"\"\n    Summarizes text using a pre-trained T5 model with advanced parameters.\n    \n    Args:\n        text (str): Input text to summarize.\n        max_input_length (int): Maximum length of the input text (default 1024 tokens).\n        max_summary_length (int): Maximum length of the summary (default 150 tokens).\n        temperature (float): Temperature for sampling (default 1.0).\n        top_k (int): Top-k sampling (default 50).\n        top_p (float): Top-p sampling (default 0.95).\n        beam_width (int): Number of beams for beam search (default 8).\n        no_repeat_ngram_size (int): N-gram size to avoid repetition (default 2).\n    \n    Returns:\n        str: Summarized text.\n    \"\"\"\n    # Tokenize the input text with truncation if it's too long\n    inputs = summarization_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n    \n    # Generate the summary with advanced settings\n    outputs = summarization_model.generate(\n        inputs,\n        max_length=max_summary_length, \n        min_length=25,\n        length_penalty=2.0, \n        num_beams=beam_width,\n        no_repeat_ngram_size=no_repeat_ngram_size, \n        early_stopping=True,\n        temperature=temperature,\n        top_k=top_k,\n        top_p=top_p\n    )\n    \n    # Decode and return the summary\n    summary = summarization_tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return summary\n\n# # Example Usage\n# print(\"===========================================================FINAL SUMMARY=============================================================\")\n# summary = summarize_text(cleaned_text)\n# print(\"Summary:\", summary)\n# cleaned_text = \"\"\"\n# The patient is diagnosed with severe chest pain, high fever, and shortness of breath due to pneumonia.\n# Medications prescribed include ibuprofen for pain and amoxicillin for the infection.\n# The doctor recommends further evaluation and a follow-up consultation in a week.\n# \"\"\"\n# summary = summarize_text(cleaned_text)\n# print(\"Summary:\", summary)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Longformer-based Context-Aware Sentiment Analysis (Handles long texts)\ndef analyze_sentiment_longformer(text, chunk_size=512, stride=256):\n    \"\"\"\n    Analyzes sentiment of long texts using Longformer model to handle larger context.\n    \n    Args:\n        text (str): Input text for sentiment analysis (could be large documents).\n        chunk_size (int): Maximum length of tokenized input for Longformer.\n        stride (int): Overlap between chunks to maintain context.\n    \n    Returns:\n        dict: Sentiment analysis result with document-level context.\n    \"\"\"\n    # Tokenize text in chunks\n    inputs = longformer_tokenizer(text, return_tensors=\"pt\", truncation=False, padding=True)\n    input_ids = inputs['input_ids'][0]\n    \n    # If the length exceeds the maximum length, break the text into chunks\n    if len(input_ids) > chunk_size:\n        sentiment_scores = []\n        \n        # Sliding window approach: move with stride across the document\n        for i in range(0, len(input_ids), chunk_size - stride):\n            chunk = input_ids[i:i+chunk_size]\n            # Ensure chunk is of the correct length\n            if len(chunk) < chunk_size:\n                chunk = chunk + [tokenizer.pad_token_id] * (chunk_size - len(chunk))\n\n            # Perform sentiment analysis on the chunk\n            inputs_chunk = {'input_ids': torch.tensor([chunk])}\n            with torch.no_grad():\n                outputs = longformer_model(**inputs_chunk)\n                logits = outputs.logits\n                sentiment_scores.append(torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()[0])\n\n        # Average the scores from each chunk\n        avg_scores = np.mean(sentiment_scores, axis=0)\n        sentiment_label = \"POSITIVE\" if avg_scores[1] > avg_scores[0] else \"NEGATIVE\"\n        sentiment_confidence = avg_scores[1] if avg_scores[1] > avg_scores[0] else avg_scores[0]\n        return {'label': sentiment_label, 'confidence': sentiment_confidence}\n    else:\n        # If text is small, use the standard model\n        sentiment = sentiment_pipeline(text)[0]\n        return sentiment\n\n# Function to analyze sentiment for mixed or large texts with context-awareness\ndef analyze_sentiment(text, long_text=False, chunk_size=512, stride=256):\n    \"\"\"\n    Analyzes sentiment with context-awareness (Document level sentiment).\n    \n    Args:\n        text (str): The text to analyze sentiment for.\n        long_text (bool): Flag to use Longformer for large documents.\n        chunk_size (int): Maximum length of each chunk.\n        stride (int): Amount to overlap between chunks to maintain context.\n    \n    Returns:\n        dict: Sentiment label and confidence.\n    \"\"\"\n    if long_text:\n        return analyze_sentiment_longformer(text, chunk_size, stride)\n    else:\n        # If it's small text, use regular sentiment analysis model\n        sentiment = sentiment_pipeline(text)[0]\n        return sentiment\n\n# # Example Usage\n# text = \"\"\"\n# Patient Name: John Doe\n# Medical Record ID: 12345\n# Diagnosis: The patient is diagnosed with breast cancer, undergoing chemotherapy.\n# Symptoms: The patient reports feeling fatigued, nauseous, and experiencing abdominal pain.\n# Prescribed Medications: Chemotherapy drugs and pain management.\n# Treatment Plan: Start chemotherapy sessions next week and monitor for side effects.\n# \"\"\"\n\n# # Analyzing sentiment with Document Level Context\n# result = analyze_sentiment(text, long_text=True)\n# print(f\"Sentiment Analysis Result: {result}\")\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MedicalNLPipeline:\n    def process_document(self, file_path: str = None, prompt: str = None):\n        \"\"\"\n        Processes a medical document in various formats (.txt, .json, .pdf) or custom prompt through the pipeline.\n        \"\"\"\n        # Step 1: Ensure only one input is provided\n        if file_path and prompt:\n            raise ValueError(\"Please provide either a file path or a prompt, not both.\")\n        \n        # Step 2: Check if a file or prompt is provided\n        if file_path:\n            # Validate the file path\n            if not os.path.isfile(file_path):\n                raise FileNotFoundError(f\"The file '{file_path}' does not exist. Please provide a valid file path.\")\n            \n            # Extract text from the provided file\n            extracted_text = extract_text_from_file(file_path)\n        elif prompt:\n            # Use the provided prompt directly\n            extracted_text = prompt\n        else:\n            raise ValueError(\"No input provided. Either a file path or a prompt must be specified.\")\n        \n        # Step 3: Preprocess the extracted text\n        cleaned_text = preprocess_text(extracted_text)\n        print(\"Cleaned Text:\", cleaned_text)\n\n\n        # Step 4: Prompt Engineering (Enhance or Format Text)\n        engineered_prompt = apply_prompt_engineering(cleaned_text)\n        print(\"Engineered Prompt:\", engineered_prompt)\n    \n        # Step 5: Extract Entities using NER pipeline\n        categorized_entities = extract_entities(cleaned_text)\n        print(\"Categorized Entities:\", categorized_entities)\n        \n    \n        # Step 6: Summarize the text\n        summary = summarize_text(cleaned_text)\n        print(\"Summary:\", summary)\n        \n        # Step 7: Perform sentiment analysis\n        sentiment_result = analyze_sentiment(cleaned_text)\n        print(\"Sentiment Analysis:\", sentiment_result)\n        \n\n        # Step 8: Return all results as a dictionary for easy access\n        return {\n            'extracted_text': extracted_text,\n            'cleaned_text': cleaned_text,\n            'engineered_prompt': engineered_prompt,\n            'categorized_entities': categorized_entities,\n            'summary': summary,\n            'sentiment': sentiment_result\n        }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading The Final Pipeline MedicalNLPipeline:","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # You can either provide a file or a custom prompt\n# medical_nlp = MedicalNLPipeline()\n# file_path = \"/kaggle/input/final-dataset/medical_document.txt\"\n# result = medical_nlp.process_document(file_path=file_path)\n\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# # Final Output Results\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"Final  Out puts\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(result)\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")\n# print(\"------------------------------------------------------------------------------------------------------------\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # # Example Usage\n# Using the EHR text \n# # raw_text = ''\n\n# # # Instantiate the Medical NLP pipeline\n# # medical_nlp = MedicalNLPipeline()\n\n# # # Process the medical document\n# # result = medical_nlp.process_document(raw_text)\n\n# # # Output the results\n# # print(\"Final Output:\")\n# # print(result)\n\n# # Example Usage\n# # file_path = \"/kaggle/input/synthea-dataset-jsons-ehr/fhir/00/000/0003292a-9bb8-4119-aa00-43d9ce567d34.json\"  # Can be .txt, .json, or .pdf\n# prompt_text = \" \"\n# # Instantiate the Medical NLP pipeline\n# medical_nlp = MedicalNLPipeline()\n\n# # Process the medical document with file or prompt\n# result = medical_nlp.process_document(prompt=prompt_text)  # Or use: result = medical_nlp.process_document(prompt=prompt_text)\n\n# # Output the results\n# print(\"Final Output:\")\n# print(result)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Test prompt \n\n# # For Test Purpose\n# prompt_text='the patient is diagnosed with the cancer and heart conditions.'\n\n# medical_nlp_pipeline = MedicalNLPipeline()\n\n# # Pass the EHR document as a prompt\n# result = medical_nlp_pipeline.process_document(prompt=prompt_text)\n\n# # Print the results\n# print(\"Pipeline Output:\", result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # New Prompt testing code\n\n# # Sample medical document (this could be extracted from a file or provided as input)\n# medical_text = \"\"\"\n# The patient, a 55-year-old male, presents with severe chest pain and shortness of breath. \n# He has a history of hypertension and diabetes. The patient reports having persistent discomfort in the chest, \n# radiating pain towards the left arm. Initial diagnosis indicates myocardial infarction. \n# The patient is currently on aspirin and nitroglycerin and is advised to undergo immediate treatment.\n# \"\"\"\n\n# # Create an instance of the MedicalNLPipeline\n# nlp_pipeline = MedicalNLPipeline()\n\n# # Process the document using the pipeline (you can either use a file path or a direct prompt as input)\n# result = nlp_pipeline.process_document(prompt=medical_text)\n\n# # # Print the results\n# # print(\"Processing Results:\")\n# # print(f\"Extracted Text: {result['extracted_text']}\")\n# # print(f\"Cleaned Text: {result['cleaned_text']}\")\n# # print(f\"Engineered Prompt: {result['engineered_prompt']}\")\n# # print(f\"Categorized Entities: {result['categorized_entities']}\")\n# # print(f\"Summary: {result['summary']}\")\n# # print(f\"Sentiment Analysis: {result['sentiment']}\")\n# # print(f\"Medical Classification: {result['medical_classification']}\")\n# print(result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Will complete Some detail Functions Tommorow   ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Started coding for this notebook now ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Some issues in this notebook ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Testing the pipeline more throughly using different prompts ‚úÖ‚úÖ ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# will  see tommorow. ‚úÖ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Notebook Done ‚úÖ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}