{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:05:44.107009Z","iopub.execute_input":"2025-05-15T19:05:44.107334Z","iopub.status.idle":"2025-05-15T19:05:45.300798Z","shell.execute_reply.started":"2025-05-15T19:05:44.107303Z","shell.execute_reply":"2025-05-15T19:05:45.299689Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Install required libraries\n!pip install monai torch torchvision transformers gradio pydicom SimpleITK opencv-python-headless pylibjpeg pylibjpeg-libjpeg\n!pip install -q datasets accelerate\n\nimport os\nimport logging\nimport re\nimport pydicom\nimport numpy as np\nfrom datetime import datetime\nfrom PIL import Image\nimport torch\nimport cv2\nimport SimpleITK as sitk\nfrom monai.transforms import (\n    Compose,\n    EnsureChannelFirst,\n    ScaleIntensity,\n    Resize,\n    ToTensor\n)\nfrom monai.networks.nets import DenseNet121\nfrom transformers import (\n    BlipProcessor,\n    BlipForConditionalGeneration,\n    AutoTokenizer,\n    BertLMHeadModel\n)\nimport gradio as gr\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nfrom typing import Tuple, Dict, Optional\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n)\nlogger = logging.getLogger(__name__)\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlogger.info(f\"Using device: {device}\")\n\n# Constants\nCONFIG = {\n    \"image_size\": [512, 512],\n    \"blip_model\": \"Salesforce/blip-image-captioning-large\",\n    \"llm_model\": \"emilyalsentzer/Bio_ClinicalBERT\",\n    \"monai_model\": \"DenseNet121\",\n    \"num_classes\": 14,\n    \"class_names\": [\n        \"No Finding\", \"Enlarged Cardiomediastinum\", \"Cardiomegaly\",\n        \"Lung Opacity\", \"Lung Lesion\", \"Edema\", \"Consolidation\",\n        \"Pneumonia\", \"Atelectasis\", \"Pneumothorax\", \"Pleural Effusion\",\n        \"Pleural Other\", \"Fracture\", \"Support Devices\"\n    ]\n}\n\n# Initialize assets\ndef initialize_assets():\n    \"\"\"Create required JSON files if they don't exist\"\"\"\n    assets = {\n        \"medical_terminology.json\": {\n            \"opacity\": \"radiographic opacity\",\n            \"shadow\": \"opacity\",\n            \"heart\": \"cardiac silhouette\",\n            \"bone\": \"osseous structures\",\n            \"lung\": \"pulmonary parenchyma\"\n        },\n        \"report_templates.json\": {\n            \"full_report\": {\n                \"comparison\": \"Comparison is made with prior studies when available.\\n\\n{findings}\",\n                \"technique\": \"Standard radiographic technique was employed.\",\n                \"findings\": \"{findings}\",\n                \"impression\": \"{impression}\"\n            }\n        }\n    }\n    \n    for filename, content in assets.items():\n        if not os.path.exists(filename):\n            with open(filename, \"w\") as f:\n                json.dump(content, f)\n            logger.info(f\"Created {filename}\")\n\ninitialize_assets()\n\nclass MedicalImageLoader:\n    \"\"\"Robust medical image loader with multiple fallback methods\"\"\"\n    \n    @staticmethod\n    def load_image(image_path: str) -> Tuple[Optional[np.ndarray], Optional[str]]:\n        \"\"\"\n        Load medical image using multiple methods with comprehensive error handling\n        \n        Args:\n            image_path: Path to the image file\n            \n        Returns:\n            tuple: (image_array, error_message)\n        \"\"\"\n        try:\n            if not os.path.exists(image_path):\n                return None, f\"File not found: {image_path}\"\n            \n            if image_path.lower().endswith('.dcm'):\n                return MedicalImageLoader._load_dicom(image_path)\n            else:\n                return MedicalImageLoader._load_standard_image(image_path)\n                \n        except Exception as e:\n            error_msg = f\"Image loading failed: {str(e)}\"\n            logger.error(error_msg)\n            return None, error_msg\n    \n    @staticmethod\n    def _load_dicom(path: str) -> Tuple[Optional[np.ndarray], Optional[str]]:\n        \"\"\"Load DICOM file with multiple fallback methods\"\"\"\n        # Method 1: SimpleITK\n        try:\n            img_sitk = sitk.ReadImage(path)\n            img_np = sitk.GetArrayFromImage(img_sitk)\n            if len(img_np.shape) == 3:  # If multi-slice, take first slice\n                img_np = img_np[0]\n            return MedicalImageLoader._normalize_dicom(img_np), None\n        except Exception as e:\n            logger.warning(f\"SimpleITK failed, trying pydicom: {e}\")\n        \n        # Method 2: pydicom\n        try:\n            ds = pydicom.dcmread(path)\n            if not hasattr(ds, 'pixel_array'):\n                return None, \"DICOM file does not contain image data\"\n            return MedicalImageLoader._normalize_dicom(ds.pixel_array), None\n        except Exception as e:\n            error_msg = f\"DICOM loading failed with both methods: {str(e)}\"\n            logger.error(error_msg)\n            return None, error_msg\n    \n    @staticmethod\n    def _load_standard_image(path: str) -> Tuple[Optional[np.ndarray], Optional[str]]:\n        \"\"\"Load standard image with multiple fallback methods\"\"\"\n        # Method 1: OpenCV\n        try:\n            img = cv2.imread(path, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n            if img is None:\n                raise ValueError(\"OpenCV returned None\")\n            return MedicalImageLoader._normalize_standard(img), None\n        except Exception as e:\n            logger.warning(f\"OpenCV failed, trying PIL: {e}\")\n        \n        # Method 2: PIL\n        try:\n            img = Image.open(path)\n            if img.mode not in ['L', 'RGB', 'RGBA']:\n                return None, f\"Unsupported image mode: {img.mode}\"\n            return MedicalImageLoader._normalize_standard(np.array(img)), None\n        except Exception as e:\n            error_msg = f\"Standard image loading failed with both methods: {str(e)}\"\n            logger.error(error_msg)\n            return None, error_msg\n    \n    @staticmethod\n    def _normalize_dicom(img: np.ndarray) -> np.ndarray:\n        \"\"\"Normalize DICOM image to 0-1 float32\"\"\"\n        if img.dtype == np.uint16:\n            img = img.astype(np.float32) / (2**16 - 1)\n        elif img.dtype == np.uint8:\n            img = img.astype(np.float32) / (2**8 - 1)\n        else:\n            img = img.astype(np.float32)\n        \n        # Convert to 3-channel if needed\n        if len(img.shape) == 2:\n            img = np.stack([img]*3, axis=-1)\n        elif img.shape[-1] == 1:\n            img = np.repeat(img, 3, axis=-1)\n        \n        return img\n    \n    @staticmethod\n    def _normalize_standard(img: np.ndarray) -> np.ndarray:\n        \"\"\"Normalize standard image to 0-1 float32\"\"\"\n        if img.dtype == np.uint16:\n            img = img.astype(np.float32) / (2**16 - 1)\n        elif img.dtype == np.uint8:\n            img = img.astype(np.float32) / (2**8 - 1)\n        else:\n            img = img.astype(np.float32)\n        \n        # Handle different channel counts\n        if len(img.shape) == 2:\n            img = np.stack([img]*3, axis=-1)\n        elif img.shape[-1] == 1:\n            img = np.repeat(img, 3, axis=-1)\n        elif img.shape[-1] == 4:  # RGBA to RGB\n            img = img[..., :3]\n        \n        return img\n\nclass MedicalImageTransformer:\n    \"\"\"Medical image transformer with robust error handling\"\"\"\n    \n    def __init__(self):\n        self.transform = Compose([\n            EnsureChannelFirst(),\n            ScaleIntensity(),\n            Resize(CONFIG[\"image_size\"]),\n            ToTensor()\n        ])\n    \n    def transform_image(self, image_array: np.ndarray) -> Tuple[Optional[torch.Tensor], Optional[str]]:\n        \"\"\"Apply transforms with comprehensive error handling\"\"\"\n        try:\n            # Ensure array is float32 and in correct range\n            if image_array.dtype != np.float32:\n                image_array = image_array.astype(np.float32)\n            \n            # Apply MONAI transforms\n            return self.transform(image_array), None\n        except Exception as e:\n            error_msg = f\"Image transformation failed: {str(e)}\"\n            logger.error(error_msg)\n            return None, error_msg\n\nclass MedicalAnalysisPipeline:\n    \"\"\"Complete medical image analysis pipeline\"\"\"\n    \n    def __init__(self):\n        self.image_loader = MedicalImageLoader()\n        self.image_transformer = MedicalImageTransformer()\n        self._init_models()\n        self._load_assets()\n    \n    def _init_models(self):\n        \"\"\"Initialize all models with proper error handling\"\"\"\n        try:\n            # BLIP model\n            self.blip_processor = BlipProcessor.from_pretrained(CONFIG[\"blip_model\"])\n            self.blip_model = BlipForConditionalGeneration.from_pretrained(\n                CONFIG[\"blip_model\"]\n            ).to(device)\n            \n            # Clinical LLM\n            self.llm_tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"llm_model\"])\n            self.llm_model = BertLMHeadModel.from_pretrained(\n                CONFIG[\"llm_model\"],\n                is_decoder=True\n            ).to(device)\n            \n            # MONAI model\n            self.monai_model = DenseNet121(\n                spatial_dims=2,\n                in_channels=3,\n                out_channels=CONFIG[\"num_classes\"]\n            ).to(device)\n            \n            # Try to load pretrained weights if available\n            if os.path.exists(\"pretrained_chexpert.pth\"):\n                self.monai_model.load_state_dict(\n                    torch.load(\"pretrained_chexpert.pth\", map_location=device)\n                )\n                logger.info(\"Loaded pretrained weights\")\n            \n            self.monai_model.eval()\n            \n        except Exception as e:\n            logger.error(f\"Model initialization failed: {e}\")\n            raise RuntimeError(f\"Could not initialize models: {e}\")\n    \n    def _load_assets(self):\n        \"\"\"Load medical terminology and templates\"\"\"\n        try:\n            with open(\"medical_terminology.json\", \"r\") as f:\n                self.med_terms = json.load(f)\n            \n            with open(\"report_templates.json\", \"r\") as f:\n                self.report_templates = json.load(f)\n                \n        except Exception as e:\n            logger.error(f\"Failed to load assets: {e}\")\n            raise RuntimeError(f\"Could not load required assets: {e}\")\n    \n    def analyze(self, image_path: str, clinical_context: str = \"\") -> Dict:\n        \"\"\"Complete analysis pipeline with comprehensive error handling\"\"\"\n        try:\n            # Step 1: Load image\n            img_array, error = self.image_loader.load_image(image_path)\n            if error:\n                return {\"error\": error}\n            \n            # Step 2: Transform image\n            img_tensor, error = self.image_transformer.transform_image(img_array)\n            if error:\n                return {\"error\": error}\n            \n            # Step 3: Generate findings\n            findings = self._generate_findings(img_tensor, clinical_context)\n            \n            # Step 4: Detect pathologies\n            pathologies = self._detect_pathologies(img_tensor)\n            \n            # Step 5: Generate report\n            report = self._generate_report(findings, pathologies)\n            \n            # Step 6: Create visualization\n            visualization = self._create_visualization(pathologies)\n            \n            return {\n                \"success\": True,\n                \"findings\": findings,\n                \"pathologies\": pathologies,\n                \"report\": report,\n                \"visualization\": visualization,\n                \"clinical_context\": clinical_context,\n                \"timestamp\": datetime.now().isoformat()\n            }\n            \n        except Exception as e:\n            error_msg = f\"Analysis pipeline failed: {str(e)}\"\n            logger.error(error_msg)\n            return {\"error\": error_msg}\n    \n    def _generate_findings(self, image_tensor: torch.Tensor, context: str) -> str:\n        \"\"\"Generate initial findings with BLIP\"\"\"\n        try:\n            img_pil = self._tensor_to_pil(image_tensor)\n            prompt = f\"Analyze this medical image. Clinical context: {context or 'None'}\"\n            \n            inputs = self.blip_processor(\n                img_pil, \n                text=prompt, \n                return_tensors=\"pt\"\n            ).to(device)\n            \n            outputs = self.blip_model.generate(\n                **inputs,\n                max_new_tokens=300,\n                num_beams=4,\n                temperature=0.7\n            )\n            \n            findings = self.blip_processor.decode(outputs[0], skip_special_tokens=True)\n            return self._enhance_terminology(findings)\n            \n        except Exception as e:\n            logger.error(f\"Findings generation failed: {e}\")\n            return \"Could not generate detailed findings\"\n    \n    def _detect_pathologies(self, image_tensor: torch.Tensor) -> Dict:\n        \"\"\"Detect pathologies using MONAI model\"\"\"\n        try:\n            with torch.no_grad():\n                outputs = self.monai_model(image_tensor.unsqueeze(0).to(device))\n                probs = torch.sigmoid(outputs).cpu().numpy()[0]\n            \n            return {\n                \"labels\": CONFIG[\"class_names\"],\n                \"probabilities\": probs.tolist(),\n                \"detected\": [\n                    CONFIG[\"class_names\"][i] \n                    for i, p in enumerate(probs) \n                    if p > 0.5\n                ]\n            }\n            \n        except Exception as e:\n            logger.error(f\"Pathology detection failed: {e}\")\n            return {\n                \"labels\": CONFIG[\"class_names\"],\n                \"probabilities\": [0.0] * len(CONFIG[\"class_names\"]),\n                \"detected\": [],\n                \"error\": \"Pathology detection failed\"\n            }\n    \n    def _generate_report(self, findings: str, pathologies: Dict) -> Dict:\n        \"\"\"Generate structured radiology report\"\"\"\n        try:\n            impression = self._get_impression(pathologies)\n            \n            return {\n                \"comparison\": self.report_templates[\"full_report\"][\"comparison\"].format(findings=findings),\n                \"technique\": self.report_templates[\"full_report\"][\"technique\"],\n                \"findings\": self._format_findings(findings, pathologies),\n                \"impression\": impression\n            }\n            \n        except Exception as e:\n            logger.error(f\"Report generation failed: {e}\")\n            return {\n                \"comparison\": \"Could not generate comparison\",\n                \"technique\": \"Standard technique\",\n                \"findings\": findings,\n                \"impression\": \"Could not generate full impression\"\n            }\n    \n    def _create_visualization(self, pathologies: Dict) -> str:\n        \"\"\"Create pathology probability plot\"\"\"\n        try:\n            plt.figure(figsize=(10, 6))\n            sns.barplot(\n                x=pathologies[\"probabilities\"],\n                y=pathologies[\"labels\"],\n                palette=\"viridis\"\n            )\n            plt.title(\"Pathology Probability Scores\")\n            plt.xlim(0, 1)\n            plt.tight_layout()\n            \n            plot_path = \"pathology_plot.png\"\n            plt.savefig(plot_path)\n            plt.close()\n            return plot_path\n            \n        except Exception as e:\n            logger.error(f\"Visualization failed: {e}\")\n            return \"\"\n    \n    def _tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:\n        \"\"\"Convert tensor to PIL Image\"\"\"\n        img = tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n        img = (img * 255).astype(np.uint8)\n        return Image.fromarray(img)\n    \n    def _get_impression(self, pathologies: Dict) -> str:\n        \"\"\"Generate impression based on pathologies\"\"\"\n        if pathologies.get(\"error\"):\n            return \"Pathology analysis unavailable\"\n            \n        if pathologies[\"detected\"]:\n            return f\"Findings consistent with: {', '.join(pathologies['detected'])}. Clinical correlation recommended.\"\n        return \"No acute cardiopulmonary abnormality detected.\"\n    \n    def _enhance_terminology(self, text: str) -> str:\n        \"\"\"Replace lay terms with medical terminology\"\"\"\n        for term, replacement in self.med_terms.items():\n            text = re.sub(rf'\\b{term}\\b', replacement, text, flags=re.IGNORECASE)\n        return text\n    \n    def _format_findings(self, findings: str, pathologies: Dict) -> str:\n        \"\"\"Highlight detected pathologies in findings\"\"\"\n        if pathologies.get(\"error\"):\n            return findings\n            \n        for path in pathologies[\"detected\"]:\n            findings = findings.replace(\n                path.lower(),\n                f\"**{path.upper()}**\"\n            )\n        return findings\n\ndef create_gradio_interface():\n    \"\"\"Create Gradio interface for the medical analysis system\"\"\"\n    analyzer = MedicalAnalysisPipeline()\n    \n    def analyze_wrapper(image_path: str, clinical_context: str) -> str:\n        \"\"\"Wrapper function for Gradio interface\"\"\"\n        result = analyzer.analyze(image_path, clinical_context)\n        \n        if result.get(\"error\"):\n            return f\"<div style='color:red;padding:20px;'><h3>Error</h3><p>{result['error']}</p></div>\"\n        \n        # Format HTML report\n        html_report = f\"\"\"\n        <div style=\"font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;\">\n            <h1 style=\"color: #2c3e50;\">Medical Imaging Analysis Report</h1>\n            <p><strong>Clinical Context:</strong> {result['clinical_context'] or 'None provided'}</p>\n            <p><em>Generated at: {result['timestamp']}</em></p>\n            \n            <h2 style=\"color: #2c3e50; border-bottom: 1px solid #3498db;\">Findings</h2>\n            <div style=\"background: #f8f9fa; padding: 15px; border-radius: 5px;\">\n                {result['report']['findings']}\n            </div>\n            \n            <h2 style=\"color: #2c3e50; border-bottom: 1px solid #3498db;\">Pathology Analysis</h2>\n            <div style=\"margin: 20px 0;\">\n                <img src=\"file/{result['visualization']}\" style=\"max-width: 100%;\">\n            </div>\n            \n            <h2 style=\"color: #2c3e50; border-bottom: 1px solid #3498db;\">Impression</h2>\n            <div style=\"background: #f8f9fa; padding: 15px; border-radius: 5px;\">\n                {result['report']['impression']}\n            </div>\n            \n            <div style=\"margin-top: 30px; font-size: 0.9em; color: #666;\">\n                <em>This AI-generated report requires verification by a qualified radiologist.</em>\n            </div>\n        </div>\n        \"\"\"\n        \n        return html_report\n    \n    with gr.Blocks() as app:\n        gr.Markdown(\"# 🏥 Medical Imaging Analysis System\")\n        \n        with gr.Row():\n            with gr.Column():\n                image_input = gr.File(\n                    label=\"Upload Medical Image\",\n                    file_types=[\".dcm\", \".png\", \".jpg\", \".jpeg\"]\n                )\n                context_input = gr.Textbox(\n                    label=\"Clinical Context (optional)\",\n                    placeholder=\"Patient symptoms or history\"\n                )\n                analyze_btn = gr.Button(\"Analyze\", variant=\"primary\")\n            \n            with gr.Column():\n                report_output = gr.HTML(\n                    label=\"Analysis Report\",\n                    value=\"<div style='text-align:center;padding:20px;'>Results will appear here</div>\"\n                )\n        \n        analyze_btn.click(\n            fn=analyze_wrapper,\n            inputs=[image_input, context_input],\n            outputs=[report_output]\n        )\n    \n    return app\n\nif __name__ == \"__main__\":\n    app = create_gradio_interface()\n    app.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:20:49.505176Z","iopub.execute_input":"2025-05-15T19:20:49.509386Z","iopub.status.idle":"2025-05-15T19:21:05.034122Z","shell.execute_reply.started":"2025-05-15T19:20:49.509285Z","shell.execute_reply":"2025-05-15T19:21:05.032784Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: monai in /usr/local/lib/python3.11/dist-packages (1.4.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.1)\nRequirement already satisfied: pydicom in /usr/local/lib/python3.11/dist-packages (3.0.1)\nRequirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.5.0)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: pylibjpeg in /usr/local/lib/python3.11/dist-packages (2.0.1)\nRequirement already satisfied: pylibjpeg-libjpeg in /usr/local/lib/python3.11/dist-packages (2.2.0)\nRequirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\nRequirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.10)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.24->monai) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.24->monai) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n* Running on local URL:  http://127.0.0.1:7861\n* Running on public URL: https://42d52c42971eca57fa.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://42d52c42971eca57fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}